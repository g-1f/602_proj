{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "train_seq_all = pd.read_csv('1d_cnn_train.csv')\n",
    "train_seq_all = train_seq_all.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0_0',\n",
       " '1_0',\n",
       " '2_0',\n",
       " '3_0',\n",
       " '4_0',\n",
       " '5_0',\n",
       " '6_0',\n",
       " '7_0',\n",
       " '8_0',\n",
       " '9_0',\n",
       " '10_0',\n",
       " '11_0',\n",
       " '12_0',\n",
       " '13_0',\n",
       " '14_0',\n",
       " '15_0',\n",
       " '16_0',\n",
       " '17_0',\n",
       " '18_0',\n",
       " '19_0',\n",
       " '20_0',\n",
       " '21_0',\n",
       " '22_0',\n",
       " '23_0',\n",
       " 'target',\n",
       " '0_1',\n",
       " '1_1',\n",
       " '2_1',\n",
       " '3_1',\n",
       " '4_1',\n",
       " '5_1',\n",
       " '6_1',\n",
       " '7_1',\n",
       " '8_1',\n",
       " '9_1',\n",
       " '10_1',\n",
       " '11_1',\n",
       " '12_1',\n",
       " '13_1',\n",
       " '14_1',\n",
       " '15_1',\n",
       " '16_1',\n",
       " '17_1',\n",
       " '18_1',\n",
       " '19_1',\n",
       " '20_1',\n",
       " '21_1',\n",
       " '22_1',\n",
       " '23_1',\n",
       " '24_1',\n",
       " '0_2',\n",
       " '1_2',\n",
       " '2_2',\n",
       " '3_2',\n",
       " '4_2',\n",
       " '5_2',\n",
       " '6_2',\n",
       " '7_2',\n",
       " '8_2',\n",
       " '9_2',\n",
       " '10_2',\n",
       " '11_2',\n",
       " '12_2',\n",
       " '13_2',\n",
       " '14_2',\n",
       " '15_2',\n",
       " '16_2',\n",
       " '17_2',\n",
       " '18_2',\n",
       " '19_2',\n",
       " '20_2',\n",
       " '21_2',\n",
       " '22_2',\n",
       " '23_2',\n",
       " '24_2',\n",
       " '0_3',\n",
       " '1_3',\n",
       " '2_3',\n",
       " '3_3',\n",
       " '4_3',\n",
       " '5_3',\n",
       " '6_3',\n",
       " '7_3',\n",
       " '8_3',\n",
       " '9_3',\n",
       " '10_3',\n",
       " '11_3',\n",
       " '12_3',\n",
       " '13_3',\n",
       " '14_3',\n",
       " '15_3',\n",
       " '16_3',\n",
       " '17_3',\n",
       " '18_3',\n",
       " '19_3',\n",
       " '20_3',\n",
       " '21_3',\n",
       " '22_3',\n",
       " '23_3',\n",
       " '24_3',\n",
       " '0_4',\n",
       " '1_4',\n",
       " '2_4',\n",
       " '3_4',\n",
       " '4_4',\n",
       " '5_4',\n",
       " '6_4',\n",
       " '7_4',\n",
       " '8_4',\n",
       " '9_4',\n",
       " '10_4',\n",
       " '11_4',\n",
       " '12_4',\n",
       " '13_4',\n",
       " '14_4',\n",
       " '15_4',\n",
       " '16_4',\n",
       " '17_4',\n",
       " '18_4',\n",
       " '19_4',\n",
       " '20_4',\n",
       " '21_4',\n",
       " '22_4',\n",
       " '23_4',\n",
       " '24_4',\n",
       " '0_5',\n",
       " '1_5',\n",
       " '2_5',\n",
       " '3_5',\n",
       " '4_5',\n",
       " '5_5',\n",
       " '6_5',\n",
       " '7_5',\n",
       " '8_5',\n",
       " '9_5',\n",
       " '10_5',\n",
       " '11_5',\n",
       " '12_5',\n",
       " '13_5',\n",
       " '14_5',\n",
       " '15_5',\n",
       " '16_5',\n",
       " '17_5',\n",
       " '18_5',\n",
       " '19_5',\n",
       " '20_5',\n",
       " '21_5',\n",
       " '22_5',\n",
       " '23_5',\n",
       " '24_5']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq_all.columns\n",
    "features = train_seq_all.drop(columns=['start_month', 'cfips', 'state', 'population_average']).columns.tolist()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(y_true, y_pred):\n",
    "    \n",
    "    # CONVERT TO NUMPY\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # WHEN BOTH EQUAL ZERO, METRIC IS ZERO\n",
    "    both = np.abs(y_true) + np.abs(y_pred)\n",
    "    idx = np.where(both==0)[0]\n",
    "    y_true[idx]=1; y_pred[idx]=1\n",
    "    \n",
    "    return 100/len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1567 county used for LSTM training, 1568 for last value filling, total county is 3135.\n"
     ]
    }
   ],
   "source": [
    "# get the cfips ranked by population\n",
    "cfips_population_decending = train_seq_all.groupby(['cfips'])['population_average'].mean().sort_values(ascending=False).reset_index().cfips\n",
    "# we use the top 50% cfips to train LSTM\n",
    "cfips_LSTM = cfips_population_decending[0: int(3135/2)]\n",
    "\n",
    "# get train data for LSTM. we only use BIG population cfips\n",
    "train_seq_LSTM = train_seq_all.loc[train_seq_all['cfips'].isin(cfips_LSTM), :]\n",
    "\n",
    "# get the cfips not used for LSTM TRAINING\n",
    "cfips_not_used = list(set(train.cfips.unique()).difference(cfips_LSTM))\n",
    "\n",
    "# print\n",
    "print(f'There are {len(cfips_LSTM)} county used for LSTM training, {len(cfips_not_used)} for last value filling, total county is {len(cfips_LSTM)+len(cfips_not_used)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate schedule: 0.001 to 0.001 to 1e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "VERBOSE = 0\n",
    "PATH_TO_MODEL = './'\n",
    "EPOCHS = 100            # 70\n",
    "BATCH_SIZE = 128       # 100\n",
    "\n",
    "SEED = 602\n",
    "\n",
    "LR_MAX = 1e-3         # 1e-3\n",
    "LR_MIN = 1e-6         # 1e-6\n",
    "\n",
    "def causal_padding(x, kernel_size):\n",
    "    pad = (kernel_size - 1)\n",
    "    return torch.nn.functional.pad(x, (pad, 0))\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(in_channels=6, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
    "        self.batchnorm = nn.BatchNorm1d(64)  # Add batch normalization layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)  # Add dropout layer\n",
    "        self.gru = nn.GRU(input_size=64, hidden_size=128, batch_first=True)\n",
    "        self.fc = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = causal_padding(x, kernel_size=3)\n",
    "        x = self.conv1d(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.transpose(1, 2)  # Transpose the dimensions\n",
    "        x, _ = self.gru(x)\n",
    "        x = self.dropout(x[:, -1, :])\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "def lrfn(epoch_i, EPOCHS):\n",
    "    decay_total_epochs = EPOCHS - 1\n",
    "    phase = math.pi * epoch_i / decay_total_epochs  # 0 ~ pi\n",
    "    cosine_decay = 0.5 * (1 + math.cos(phase))\n",
    "    lr = (LR_MAX - LR_MIN) * cosine_decay + LR_MIN\n",
    "    \n",
    "    return lr\n",
    "\n",
    "rng = [i for i in range(EPOCHS)]\n",
    "lr_y = [lrfn(x, EPOCHS) for x in rng]\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(rng, lr_y, '-o')\n",
    "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(lr_y[0], max(lr_y), lr_y[-1]))\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.ylabel('Learning Rate', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17237, 6, 25]), torch.Size([17237]), (17237,)\n"
     ]
    }
   ],
   "source": [
    "n_row = train_seq_LSTM[features].shape[0]\n",
    "reshaped = train_seq_LSTM[features].values.reshape(n_row, 6, 25)\n",
    "x = torch.tensor(reshaped, dtype=torch.float32)\n",
    "y = torch.tensor(train_seq_LSTM.loc[:, 'target'].values, dtype=torch.float32)\n",
    "groups = np.array(train_seq_LSTM.loc[:, 'cfips'])\n",
    "print(f'{x.shape}, {y.shape}, {groups.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- FOLD0 -------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 32, got 64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/gyf/JHU/Spring 22/Data Mining/Project/602_proj/1dcnn.ipynb Cell 9\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyf/JHU/Spring%2022/Data%20Mining/Project/602_proj/1dcnn.ipynb#X40sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m batch_x, batch_y \u001b[39m=\u001b[39m batch_x\u001b[39m.\u001b[39mto(device), batch_y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyf/JHU/Spring%2022/Data%20Mining/Project/602_proj/1dcnn.ipynb#X40sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gyf/JHU/Spring%2022/Data%20Mining/Project/602_proj/1dcnn.ipynb#X40sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m output \u001b[39m=\u001b[39m model(batch_x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyf/JHU/Spring%2022/Data%20Mining/Project/602_proj/1dcnn.ipynb#X40sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output\u001b[39m.\u001b[39msqueeze(), batch_y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyf/JHU/Spring%2022/Data%20Mining/Project/602_proj/1dcnn.ipynb#X40sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1488\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1485\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1486\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1487\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1488\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1489\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1490\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/gyf/JHU/Spring 22/Data Mining/Project/602_proj/1dcnn.ipynb Cell 9\u001b[0m in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyf/JHU/Spring%2022/Data%20Mining/Project/602_proj/1dcnn.ipynb#X40sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyf/JHU/Spring%2022/Data%20Mining/Project/602_proj/1dcnn.ipynb#X40sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)  \u001b[39m# Transpose the dimensions\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gyf/JHU/Spring%2022/Data%20Mining/Project/602_proj/1dcnn.ipynb#X40sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m x, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgru(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyf/JHU/Spring%2022/Data%20Mining/Project/602_proj/1dcnn.ipynb#X40sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m x \u001b[39m=\u001b[39m x[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyf/JHU/Spring%2022/Data%20Mining/Project/602_proj/1dcnn.ipynb#X40sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(x)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1488\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1485\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1486\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1487\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1488\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1489\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1490\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/torch/nn/modules/rnn.py:996\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    992\u001b[0m     \u001b[39m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    993\u001b[0m     \u001b[39m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m    994\u001b[0m     hx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m--> 996\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_forward_args(\u001b[39minput\u001b[39;49m, hx, batch_sizes)\n\u001b[1;32m    997\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    998\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mgru(\u001b[39minput\u001b[39m, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers,\n\u001b[1;32m    999\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/torch/nn/modules/rnn.py:253\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_forward_args\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]):\n\u001b[0;32m--> 253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_input(\u001b[39minput\u001b[39;49m, batch_sizes)\n\u001b[1;32m    254\u001b[0m     expected_hidden_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_hidden_size(\u001b[39minput\u001b[39m, batch_sizes)\n\u001b[1;32m    256\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_hidden_size(hidden, expected_hidden_size)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/torch/nn/modules/rnn.py:218\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    215\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput must have \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m dimensions, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    216\u001b[0m             expected_input_dim, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim()))\n\u001b[1;32m    217\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m--> 218\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    219\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    220\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 32, got 64"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "validation_pred_y_all = []  # predictions of the validation data for all the folds\n",
    "validation_y_all = []       # corresponding labels of the validation data\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "fold = 0\n",
    "for train_idx, validation_idx in gkf.split(x, y, groups=groups):\n",
    "    \n",
    "    print(f'------------------- FOLD{fold} -------------------')\n",
    "    \n",
    "    train_x = x[train_idx, :]\n",
    "    train_y = y[train_idx]\n",
    "    validation_x = x[validation_idx, :]\n",
    "    validation_y = y[validation_idx]\n",
    "\n",
    "    train_dataset = TensorDataset(train_x, train_y)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    validation_dataset = TensorDataset(validation_x, validation_y)\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model = Model().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_x)\n",
    "            loss = criterion(output.squeeze(), batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in validation_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                output = model(batch_x)\n",
    "                loss = criterion(output.squeeze(), batch_y)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(validation_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        lr = lrfn(epoch, EPOCHS)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "\n",
    "    torch.save(model.state_dict(), f'{PATH_TO_MODEL}GRU_fold_{fold+1}.pt')\n",
    "\n",
    "    # Plot train and validation loss\n",
    "    plt.figure(num=1, figsize=(25, 5))\n",
    "    plt.subplot(1, 5, fold+1)\n",
    "    plt.plot(train_losses, label='train loss')\n",
    "    plt.plot(val_losses, label='val loss')\n",
    "\n",
    "    model.eval()\n",
    "    validation_pred_y = []\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in validation_loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            output = model(batch_x)\n",
    "            validation_pred_y.extend(output.squeeze().cpu().numpy())\n",
    "    validation_pred_y = np.array(validation_pred_y)\n",
    "\n",
    "    smape_1_fold = smape(validation_y.numpy(), validation_pred_y)\n",
    "    trained_epoch_num = len(train_losses)\n",
    "    print(f'Fold {fold} validation smape is {smape_1_fold}, trained with {trained_epoch_num} epochs.')\n",
    "\n",
    "    validation_pred_y_all.append(validation_pred_y)\n",
    "    validation_y_all.append(validation_y.numpy())\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "plt.show()\n",
    "\n",
    "validation_pred_y_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
